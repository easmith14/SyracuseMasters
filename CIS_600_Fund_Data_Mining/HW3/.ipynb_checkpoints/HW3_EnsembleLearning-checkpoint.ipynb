{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675f8bfe",
   "metadata": {},
   "source": [
    "# Homework 3: NBC, KNN, and Ensemble Learning\n",
    "## CIS600\n",
    "## Evan Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20929bab",
   "metadata": {},
   "source": [
    "#### Data Loading and EDA\n",
    "First, we import the data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "de4f6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"C:/Users/evana/Documents/GitHub/SyracuseMasters/CIS_600_Fund_Data_Mining/HW3/Disease Prediction Testing.csv\")\n",
    "train = pd.read_csv(\"C:/Users/evana/Documents/GitHub/SyracuseMasters/CIS_600_Fund_Data_Mining/HW3/Disease Prediction Training.csv\")\n",
    "\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bb2cf",
   "metadata": {},
   "source": [
    "We then define and use two functions: one to display the null values per row and one for the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9385f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Report\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High Blood Pressure</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Low Blood Pressure</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smoke</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Exercise</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Disease</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column  Unique Values  Nulls\n",
       "0                   Age             28      0\n",
       "1                Gender              2      0\n",
       "2                Height            101      0\n",
       "3                Weight            248      0\n",
       "4   High Blood Pressure            143      0\n",
       "5    Low Blood Pressure            143      0\n",
       "6           Cholesterol              3      0\n",
       "7               Glucose              3      0\n",
       "8                 Smoke              2      0\n",
       "9               Alcohol              2      0\n",
       "10             Exercise              2      0\n",
       "11              Disease              2      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Report\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Nulls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>21000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Height</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weight</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High Blood Pressure</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Low Blood Pressure</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smoke</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Exercise</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column  Unique Values  Nulls\n",
       "0                    ID          21000      0\n",
       "1                   Age             27      0\n",
       "2                Gender              2      0\n",
       "3                Height             81      0\n",
       "4                Weight            182      0\n",
       "5   High Blood Pressure            115      0\n",
       "6    Low Blood Pressure             92      0\n",
       "7           Cholesterol              3      0\n",
       "8               Glucose              3      0\n",
       "9                 Smoke              2      0\n",
       "10              Alcohol              2      0\n",
       "11             Exercise              2      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def DisplayNullRows (df):\n",
    "    dataCleaningCounts = []\n",
    "    for col in df.columns:\n",
    "        dataCleaningCounts.append([col, df[col].nunique(), df[col].isnull().sum()])\n",
    "    display(pd.DataFrame(dataCleaningCounts, columns = ['Column', 'Unique Values', 'Nulls']))\n",
    "    return\n",
    "\n",
    "print(\"Training Data Report\")\n",
    "DisplayNullRows(train)\n",
    "print(\"Testing Data Report\")\n",
    "DisplayNullRows(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e86a1",
   "metadata": {},
   "source": [
    "We see that there are no null rows in either the test or training set, and all columns contain information (they have at least 2 unique values).\n",
    "\n",
    "Next, we convert all non-numeric fields such that the various classifiers can process the inputs. First we determine the columns that need conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b31ff402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Cholesterol', 'Glucose'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a0ed8",
   "metadata": {},
   "source": [
    "Since many of these columns have an ordering that is important to capture, we manually dictate the encoding and update the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6822835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumerizeObjectColumns(df):\n",
    "    \n",
    "    df['Gender'] = df['Gender'].apply(lambda x: ['female', 'male'].index(x))\n",
    "    df['Cholesterol'] = df['Cholesterol'].apply(lambda x: ['normal', 'high', 'too high'].index(x))\n",
    "    df['Glucose'] = df['Glucose'].apply(lambda x: ['normal', 'high', 'too high'].index(x))\n",
    "    \n",
    "    return\n",
    "\n",
    "NumerizeObjectColumns(train)\n",
    "NumerizeObjectColumns(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f1cf8",
   "metadata": {},
   "source": [
    "Now we look to see if there are any notable outliers, starting by looking at the range of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c0331c1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2052/3326088068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in train.columns:\n",
    "    x[col].append(col.max())\n",
    "    \n",
    "\n",
    "\n",
    "display(pd.DataFrame(x, columns = ['Max', 'Min', 'Range']))\n",
    "\n",
    "display(train.max() - train.min(), \"\\n\\n\",train.max(), \"\\n\\n\",train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984dc659",
   "metadata": {},
   "source": [
    "Finally, we normalize all fields to ensure that we are using a scaled form of the data that will work well in our classifiers and then split them into testing and training sets using a fixed random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "385e1c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size is (34300, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = train.drop('Disease', axis=1)\n",
    "y = train['Disease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "print(f\"train data size is {X_train.shape}\")\n",
    "\n",
    "Y_train = train[-1:]\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9376c",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "For this classifier, we select the most critical parameters to tune. In this case, we want to learn from class prior probabilities, so we only need to vary `binarize` and `alpha`. We oscillate these values around the default values and select the best performing model by accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe71a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=BernoulliNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0, 0.1, 0.5, 1, 1.5],\n",
       "                         'binarize': [0, 0.1, 0.3, 0.8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {'binarize': [0, 0.3, 0.8],\n",
    "              'alpha': [0, 0.5, 1, 1.5]}\n",
    "\n",
    "clf_nbc = GridSearchCV(BernoulliNB(), param_grid, n_jobs=-1, scoring='accuracy')\n",
    "t = clf_nbc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4022e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.34%\n",
      "Accuracy: 71.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0, 'binarize': 0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Output Best Model Hyperparameters\n",
    "print(f\"Accuracy: {round(clf_nbc.best_score_*100, 2)} %\")\n",
    "%ddir\n",
    "display(clf_nbc.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96608a2b",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Classifier\n",
    "\n",
    "For this classifier, we select the most critical parameters to tune. In this case, that is `weights`, `n_neighbors`, and `leaf_size`. We oscillate these values around the default values and select the best performing model by accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d5d3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'weights': ['uniform', 'distance'],\n",
    "              'n_neighbors': [4, 5, 6],\n",
    "              'leaf_size': [25, 30, 35]}\n",
    "clf_knn = GridSearchCV(KNeighborsClassifier(n_jobs=-1), param_grid, n_jobs=-1, scoring='accuracy')\n",
    "clf_knn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a41f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.51%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 25,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': -1,\n",
       " 'n_neighbors': 4,\n",
       " 'p': 2,\n",
       " 'weights': 'distance'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Output Best Model Hyperparameters\n",
    "print(f\"Accuracy: {round(clf_knn.best_score_*100, 2)}%\")\n",
    "\n",
    "display(clf_knn.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a718f7",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "For the Random Forest Classifier, we chose to vary our parameters over the `n_estimators`, which controls the number of trees that are generated for each fold, and `max_features`, both of which are oscillated around the default. \n",
    "\n",
    "This classifier also is the first time we use a custom model selection object, with a 10-fold version overriding the default 5-fold to improve the consistency of accuracy measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c18e3ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=16, shuffle=True),\n",
       "             estimator=RandomForestClassifier(n_jobs=-1, random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_features': [3, 5, 7],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_features': [3, 5, 7]}\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=random_seed)\n",
    "\n",
    "clf_rfc = GridSearchCV(RandomForestClassifier(n_jobs=-1, random_state=random_seed), param_grid, n_jobs=-1, scoring='accuracy', cv=cv)\n",
    "t = clf_rfc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef62f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 3,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 150,\n",
       " 'n_jobs': -1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 123,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Output Best Model Hyperparameters\n",
    "print(f\"Accuracy: {round(clf_rfc.best_score_*100, 2)}%\")\n",
    "\n",
    "display(clf_rfc.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65975d83",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine\n",
    "\n",
    "The GBM has very similar parameters to the Random Forest, in that we will vary the `n_estimators` parameter. In this case, that parameter interacts strongly with the `learning_rate`, since they act in a similar space but with opposite effects. The `max_depth` param is recommended for tuning within the documentation, so we vary it +-1 from the original default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d0a051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {'n_estimators': [100, 150],\n",
    "              'learning_rate': [0.1, 0.3, 0.5],\n",
    "              'max_depth': [2, 3, 4]}\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=random_seed)\n",
    "\n",
    "clf_gbm = GridSearchCV(GradientBoostingClassifier(random_state=random_seed), param_grid, n_jobs=-1, scoring='accuracy', cv=cv)\n",
    "t = clf_gbm.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Tuning\n",
    "\n",
    "param_grid = {'learning_rate': [0.02, 0.1, 0.02],\n",
    "              'n_estimators': [60, 160, 50],\n",
    "              'max_depth': [2, 5]}\n",
    "clf = GridSearchCV(gbm(), param_grid)\n",
    "clf.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354f2c0",
   "metadata": {},
   "source": [
    "### Generating Predictions\n",
    "\n",
    "We can summarize the selected and tuned models and compare them by accuracy alongside their hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7344873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Naive Bayes\n",
      "\tAccuracy: 71.34%\n",
      "\tParams: {'alpha': 0, 'binarize': 0, 'class_prior': None, 'fit_prior': True}\n",
      "\n",
      "Model Name: K-Nearest Neighbors\n",
      "\tAccuracy: 63.51%\n",
      "\tParams: {'algorithm': 'auto', 'leaf_size': 25, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Model Name: Random Forest\n",
      "\tAccuracy: 73.81%\n",
      "\tParams: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def printModelSummary(model):\n",
    "    print(f\"Model Name: {model['Name']}\")\n",
    "    print(f\"\\tAccuracy: {round(model['Clf'].best_score_*100, 2)}%\")\n",
    "    print(f\"\\tParams: {model['Clf'].best_estimator_.get_params()}\\n\")\n",
    "    return\n",
    "\n",
    "modelSet = [{'Name':\"Naive Bayes\", 'Clf':clf_nbc},\n",
    "            {'Name':\"K-Nearest Neighbors\", 'Clf':clf_knn},\n",
    "            {'Name':\"Random Forest\", 'Clf':clf_rfc},\n",
    "            {'Name':\"Gradient Boosting Machine\", 'Clf':clf_gbm}\n",
    "           ]\n",
    "\n",
    "for model in modelSet:\n",
    "    printModelSummary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a203f2",
   "metadata": {},
   "source": [
    "We now take those tuned classifiers and use each of them to produce a set of predictions for the output set. We then save those predictions to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fe344ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2052/502052413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m          \u001b[1;34m'KNN'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mclf_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m          \u001b[1;34m'RF'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mclf_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m          'GBM' : clf_gbm.predict(test_data)}\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moutputData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_gbm' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = test.drop('ID', axis=1)\n",
    "\n",
    "frame = {'ID': test['ID'],\n",
    "         'NBC' : clf_nbc.predict(test_data),\n",
    "         'KNN' : clf_knn.predict(test_data),\n",
    "         'RF' : clf_rfc.predict(test_data),\n",
    "         'GBM' : clf_gbm.predict(test_data)}\n",
    "\n",
    "outputData = pd.DataFrame(frame)\n",
    "outputData.to_csv('HW3_output_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
